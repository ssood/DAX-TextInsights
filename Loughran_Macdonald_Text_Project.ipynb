{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssood/DAX-TextInsights/blob/main/Loughran_Macdonald_Text_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV99bGyEtw-U"
      },
      "source": [
        "<b>This project focuses on extracting words from a document.\n",
        "Words match one of two different lists of Loughran-McDonald sentiment of negative, litigious and uncertain words.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tlo41wgitw-V"
      },
      "source": [
        "<b>Step 1: </b>Import negative word list and uncertainty word list into Python as two separate lists ($list\\_neg$, $list\\_unc$). Print the length of each list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6vZt7Tntw-V"
      },
      "outputs": [],
      "source": [
        "def Input(filename):\n",
        "    f = open(filename, 'r')\n",
        "    text = f.read()                             # Reads entire file into one long string (containing line breaks)\n",
        "    words = text.replace('\\n',' ').split(' ')  # Converts string into list by splitting on ' '\n",
        "    words = [w for w in words if w != '']      #drops empty strings\n",
        "    f.close()\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIMkK5uHtw-W"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "doc = Input('/content/sample_data/HW6_Enron_10K_19931231.txt') #prior function in use for Enron document and sentiment words\n",
        "neg = Input('/content/sample_data/LM_negative.txt')\n",
        "unc = Input('/content/sample_data/LM_uncertainty.txt')\n",
        "\n",
        "list_neg = []     #list of negative words\n",
        "for w in neg:\n",
        "    list_neg.append(w)\n",
        "\n",
        "list_unc = []     #list of uncertain words\n",
        "for w in unc:\n",
        "    list_unc.append(w)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP8ryDnNtw-W",
        "outputId": "bdae131c-3671-44ca-a905-e4b2d212b0a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list_neg: 2355\n",
            "list_unc: 297\n"
          ]
        }
      ],
      "source": [
        "print(\"list_neg:\", len(list_neg))\n",
        "print(\"list_unc:\", len(list_unc)) #prints out the length of the lists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhjSYPCltw-W"
      },
      "source": [
        "<b>Step 2:</b> Use a for loop or list comprehension to drop any words from the negative word list that appear in the uncertainty word list. Name the new lists $list\\_neg2 and list\\_unc2,$. Print the length of each list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51nvmlQAtw-W"
      },
      "outputs": [],
      "source": [
        "list_neg2 = []           #new list of non-overlapping negative words\n",
        "for w in list_neg:\n",
        "    if w not in list_unc:\n",
        "        list_neg2.append(w)\n",
        "list_unc2 = []           #new list of non-overlapping uncertain words\n",
        "for w in list_unc:\n",
        "    if w not in list_neg:\n",
        "            list_unc2.append(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOgy0uo0tw-X",
        "outputId": "8b109b59-ebfe-4171-92a8-1ed0e8e7610d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list_neg2: 2315\n",
            "list_unc2: 257\n"
          ]
        }
      ],
      "source": [
        "print(\"list_neg2:\", len(list_neg2))\n",
        "print(\"list_unc2:\", len(list_unc2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZj8K5RfD-tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kW-vIrhtw-X"
      },
      "source": [
        "<b>Step 3:</b> Import the document assigned to you as a single string. Use <b>.replace()</b> to remove all punctuation (i.e., ',' '.' '-' ';' ':' '!' '?' '(' ')' '[' ']') and tabs (i.e. \\t) and line returns (i.e. \\n). Use <b>.split()</b> and <b>.upper()</b> to convert the string into a list of uppercase words. Name this list $filing\\_w$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6tMqqrntw-X"
      },
      "outputs": [],
      "source": [
        "doc = Input('/content/sample_data/HW6_Enron_10K_19931231.txt')\n",
        "x = open('/content/sample_data/HW6_Enron_10K_19931231.txt', 'r') #opens the Enron document that has been formed in a list\n",
        "text = x.read()\n",
        "text = text.replace(',', ' ')\n",
        "text = text.replace('.',' ')\n",
        "text = text.replace('-', ' ')\n",
        "text = text.replace(';', ' ')\n",
        "text = text.replace(':', ' ')\n",
        "text = text.replace('!', ' ')\n",
        "text = text.replace('?', ' ')\n",
        "text = text.replace('(', ' ')\n",
        "text = text.replace(')', ' ')\n",
        "text = text.replace('[', ' ')\n",
        "text = text.replace(']', ' ')\n",
        "text = text.replace('\\t', ' ')\n",
        "text = text.replace('\\n', ' ')\n",
        "text = text.replace('<', ' ')\n",
        "text = text.replace('/', ' ')\n",
        "text = text.replace('>', ' ')\n",
        "filing_w = text.upper().split() #new list with punctuations removed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjdTZlUxtw-X"
      },
      "source": [
        "<b>Step 4:</b> Create the dictionary $dcount$ and use it to count how often each of the words on the two word lists appears in your document. Your dictionary does not need to include any word list words that do not appear in your document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrVSM61Ztw-X"
      },
      "outputs": [],
      "source": [
        "dcount1 = {}                 #new dictionary dcount1\n",
        "for w in list_neg2:          #all lists will start with words with 0 value\n",
        "    dcount1.setdefault(w, 0)\n",
        "for w in list_unc2:\n",
        "    dcount1.setdefault(w, 0)\n",
        "\n",
        "for w in filing_w:          #dictionary is counting repeated words\n",
        "    if w in dcount1:\n",
        "        dcount1[w] += 1\n",
        "\n",
        "dcount = {}                 #transferring the keys of dcount1 to new dictionary dcount\n",
        "for keys in dcount1:\n",
        "    if dcount1[keys] > 0:\n",
        "        dcount[keys] = dcount1[keys]\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eQfx6NGtw-X"
      },
      "source": [
        "<b>Step 5:</b> Create a new list $list\\_tup$ containing tuples of the form ($word$, $type$, $count$), where $word$ is a word in the three word lists, $type$ is 'Negative'or 'Uncertainty', and $count$ is the count of each word in your document. The list should only contain words that appear at least once in your document. Words should be lowercase except for the first letter, which is capitalized. You should use the code below to print the first ten tuples in the sorted list.\n",
        "\n",
        "If helpful, you are welcome to create a separate dictionary that maps each word list word to 'Negative'or 'Uncertainty'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LNHRkMytw-X"
      },
      "outputs": [],
      "source": [
        "dneg = {}     #new dictionary of negative words\n",
        "list_tup = []\n",
        "for w in list_neg2:\n",
        "    dneg.setdefault(w, 0)\n",
        "dunc = {}     #new dictionary of uncertain words\n",
        "for w in list_unc2:\n",
        "    dunc.setdefault(w, 0)\n",
        "\n",
        "for w in dcount:\n",
        "    sub = [] #new list that appends variable word\n",
        "    word = w[0] + w[1:].lower()\n",
        "    sub.append(word)\n",
        "    if w in dneg: #appending overlapping words\n",
        "        sub.append('Negative')\n",
        "    elif w in dunc:\n",
        "        sub.append('Uncertain')\n",
        "    sub.append(dcount[w]) #adding the amount of times appeared\n",
        "    tup = tuple(sub)\n",
        "    list_tup.append(tup) #list of tuples appended"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDrcO-89tw-X"
      },
      "source": [
        "<b>Step 6:</b> Create a new list $list\\_top$ that contains the tuples of the ten most frequent words of each type ('Negative', 'Uncertain') sorted from most frequent to least frequent. In other words, this list should consist of 30 tuples, where ten tuples are for the most frequent 'Negative' words, another ten tuples are for the most frequent 'Uncertainty', and the last ten tuples are for the most frequent 'Litigious'. Do not worry about including additional words if the tenth-most frequent word has the same count as the eleventh-most frequent word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZhauVZJtw-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66f4dc1-190d-4b14-95e9-1efba7dbff71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "list_top = [] #new list of tuples of frequent words sorted\n",
        "negs = []\n",
        "uncs = []\n",
        "\n",
        "def thirdval(tup): #function that returns amount of times the word in question is used\n",
        "    return tup[2]\n",
        "\n",
        "\n",
        "for tup in list_tup: #for loop that appends list of corresponding type of words\n",
        "    if tup[1] == 'Negative':\n",
        "        negs.append(tup)\n",
        "    if tup[1] == 'Uncertain':\n",
        "        uncs.append(tup)\n",
        "\n",
        "negs.sort(reverse = True, key=thirdval) #sorting the list of type of words using the function above\n",
        "uncs.sort(reverse = True, key=thirdval)\n",
        "\n",
        "list_top = uncs[:10]  + negs[:10] #list of most frequent 10 words of each type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7vDdqRutw-Y"
      },
      "outputs": [],
      "source": [
        "for l in list_top: #results\n",
        "    print(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1fJLeA5tw-Y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}