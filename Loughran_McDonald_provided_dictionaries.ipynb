{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrpJU/qJWXjmQduRkYjL77",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssood/DAX-TextInsights/blob/main/Loughran_McDonald_provided_dictionaries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/sample_data/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCt1yCzbMnjy",
        "outputId": "62a0f2e4-2c48-445f-cbaf-fa90c59997d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3GKylvt3I9pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh85LZ4aG5gz",
        "outputId": "661c0ecf-fae1-425b-8c34-4d1d7c436558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Program to provide generic parsing for all files in a user-specified directory.\n",
        "The program assumes the input files have been scrubbed,\n",
        "  i.e., HTML, ASCII-encoded binary, and any other embedded document structures that are not\n",
        "  intended to be analyzed have been deleted from the file.\n",
        "\n",
        "Dependencies:\n",
        "    Python:  MOD_Load_MasterDictionary_vxxxx.py\n",
        "    Data:    LoughranMcDonald_MasterDictionary_XXXX.csv\n",
        "\n",
        "The program outputs:\n",
        "   1.  File name\n",
        "   2.  File size (in bytes)\n",
        "   3.  Number of words (based on LM_MasterDictionary\n",
        "   4.  Proportion of positive words (use with care - see LM, JAR 2016)\n",
        "   5.  Proportion of negative words\n",
        "   6.  Proportion of uncertainty words\n",
        "   7.  Proportion of litigious words\n",
        "   8.  Proportion of modal-strong words\n",
        "   9.  Proportion of modal-weak words\n",
        "  10.  Proportion of constraining words (see Bodnaruk, Loughran and McDonald, JFQA 2015)\n",
        "  11.  Number of alphanumeric characters (a-z, A-Z)\n",
        "  12.  Number of digits (0-9)\n",
        "  13.  Number of numbers (collections of digits)\n",
        "  14.  Average number of syllables\n",
        "  15.  Average word length\n",
        "  16.  Vocabulary (see Loughran-McDonald, JF, 2015)\n",
        "\n",
        "  ND-SRAF\n",
        "  McDonald 201606 : updated 201803; 202107; 202201\n",
        "\"\"\"\n",
        "\n",
        "import csv\n",
        "import glob\n",
        "import re\n",
        "import string\n",
        "import sys\n",
        "import datetime as dt\n",
        "import MOD_Load_MasterDictionary_v2022 as LM\n",
        "\n",
        "# User defined directory for files to be parsed\n",
        "TARGET_FILES = r'/content/sample_data/Test/*.pdf'\n",
        "# User defined file pointer to LM dictionary\n",
        "MASTER_DICTIONARY_FILE = '/content/sample_data/Loughran-McDonald_MasterDictionary_1993-2021.csv'\n",
        "# User defined output file\n",
        "OUTPUT_FILE = r'/content/sample_data/Parser.csv'\n",
        "# Setup output\n",
        "OUTPUT_FIELDS = ['file name', 'file size', 'number of words', '% negative', '% positive',\n",
        "                 '% uncertainty', '% litigious', '% strong modal', '% weak modal',\n",
        "                 '% constraining', '# of alphabetic', '# of digits',\n",
        "                 '# of numbers', 'avg # of syllables per word', 'average word length', 'vocabulary']\n",
        "\n",
        "lm_dictionary = LM.load_masterdictionary(MASTER_DICTIONARY_FILE, print_flag=True)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    f_out = open(OUTPUT_FILE, 'w')\n",
        "    wr = csv.writer(f_out, lineterminator='\\n')\n",
        "    wr.writerow(OUTPUT_FIELDS)\n",
        "\n",
        "    file_list = glob.glob(TARGET_FILES)\n",
        "    n_files = 0\n",
        "    for file in file_list:\n",
        "        n_files += 1\n",
        "        print(f'{n_files:,} : {file}')\n",
        "        with open(file, 'r', encoding='UTF-8', errors='ignore') as f_in:\n",
        "            doc = f_in.read()\n",
        "        doc = re.sub('(May|MAY)', ' ', doc)  # drop all May month references\n",
        "        doc = doc.upper()  # for this parse caps aren't informative so shift\n",
        "\n",
        "        output_data = get_data(doc)\n",
        "        output_data[0] = file\n",
        "        output_data[1] = len(doc)\n",
        "        wr.writerow(output_data)\n",
        "        if n_files == 100: break\n",
        "\n",
        "\n",
        "def get_data(doc):\n",
        "\n",
        "    vdictionary = dict()\n",
        "    _odata = [0] * 16\n",
        "    total_syllables = 0\n",
        "    word_length = 0\n",
        "\n",
        "    tokens = re.findall('\\w+', doc)  # Note that \\w+ splits hyphenated words\n",
        "    for token in tokens:\n",
        "        if not token.isdigit() and len(token) > 1 and token in lm_dictionary:\n",
        "            _odata[2] += 1  # word count\n",
        "            word_length += len(token)\n",
        "            if token not in vdictionary:\n",
        "                vdictionary[token] = 1\n",
        "            if lm_dictionary[token].negative: _odata[3] += 1\n",
        "            if lm_dictionary[token].positive: _odata[4] += 1\n",
        "            if lm_dictionary[token].uncertainty: _odata[5] += 1\n",
        "            if lm_dictionary[token].litigious: _odata[6] += 1\n",
        "            if lm_dictionary[token].strong_modal: _odata[7] += 1\n",
        "            if lm_dictionary[token].weak_modal: _odata[8] += 1\n",
        "            if lm_dictionary[token].constraining: _odata[9] += 1\n",
        "            total_syllables += lm_dictionary[token].syllables\n",
        "\n",
        "    _odata[10] = len(re.findall('[A-Z]', doc))\n",
        "    _odata[11] = len(re.findall('[0-9]', doc))\n",
        "    # drop punctuation within numbers for number count\n",
        "    doc = re.sub('(?!=[0-9])(\\.|,)(?=[0-9])', '', doc)\n",
        "    doc = doc.translate(str.maketrans(string.punctuation, \" \" * len(string.punctuation)))\n",
        "    _odata[12] = len(re.findall(r'\\b[-+\\(]?[$€£]?[-+(]?\\d+\\)?\\b', doc))\n",
        "    _odata[13] = total_syllables / _odata[2]\n",
        "    _odata[14] = word_length / _odata[2]\n",
        "    _odata[15] = len(vdictionary)\n",
        "\n",
        "    # Convert counts to %\n",
        "    for i in range(3, 9 + 1):\n",
        "        _odata[i] = (_odata[i] / _odata[2]) * 100\n",
        "    # Vocabulary\n",
        "\n",
        "    return _odata\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start = dt.datetime.now()\n",
        "    print(f'\\n\\n{start.strftime(\"%c\")}\\nPROGRAM NAME: {sys.argv[0]}\\n')\n",
        "    main()\n",
        "    print(f'\\n\\nRuntime: {(dt.datetime.now()-start)}')\n",
        "    print(f'\\nNormal termination.\\n{dt.datetime.now().strftime(\"%c\")}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l-9WlyvOHFw",
        "outputId": "83c55bd1-a8c9-4e0f-bf7d-288e5a100ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ...Loading Master Dictionary 85,000\n",
            "Master Dictionary loaded from file:\n",
            "  /content/sample_data/Loughran-McDonald_MasterDictionary_1993-2021.csv\n",
            "\n",
            "  master_dictionary has 86,531 words.\n",
            "\n",
            "\n",
            "\n",
            "Thu Dec 15 09:49:20 2022\n",
            "PROGRAM NAME: /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\n",
            "\n",
            "1 : /content/sample_data/Test/BMW-Group-Q1-2022-en.pdf\n",
            "2 : /content/sample_data/Test/Beiersdorf-Q3 2022.pdf\n",
            "3 : /content/sample_data/Test/brenntagsequarterly-statementq32022.pdf\n",
            "4 : /content/sample_data/Test/brenntag-se-interim-report-q22022.pdf\n",
            "5 : /content/sample_data/Test/bayer-quarterly-statement-q1-2022.pdf\n",
            "6 : /content/sample_data/Test/Beiersdorf-first-half-of-2022.pdf\n",
            "7 : /content/sample_data/Test/BMW_Q3-2022_EN.pdf\n",
            "8 : /content/sample_data/Test/BMW_Q2-2022_EN.pdf\n",
            "9 : /content/sample_data/Test/brenntag-se-interim-report-q12022.pdf\n",
            "10 : /content/sample_data/Test/brenntag-sear2021en.pdf\n",
            "11 : /content/sample_data/Test/Beiersdorf-Annual-Report-2021-EN.pdf\n",
            "12 : /content/sample_data/Test/bayer-quarterly-statement-q3-2022.pdf\n",
            "13 : /content/sample_data/Test/BMW-Group-Report-2021-en.pdf\n",
            "14 : /content/sample_data/Test/Beiersdorf-Q1 2022.pdf\n",
            "\n",
            "\n",
            "Runtime: 0:00:03.498609\n",
            "\n",
            "Normal termination.\n",
            "Thu Dec 15 09:49:23 2022\n",
            "\n"
          ]
        }
      ]
    }
  ]
}